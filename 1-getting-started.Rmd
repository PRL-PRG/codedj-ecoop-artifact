~~~
NOTE

This is an R markdown document. It's like a markdown document, but has 
executable snippets of code that do the work (in various languages, including
bash, Python, R). It can be viewed using Rstudio---we recommend doing this.

    rstudio 1-getting-started.Rmd

It can also be executed (in whole) with R using the following bash snippet:*
 
    Rscript -e "rmarkdown::render('1-getting-started.Rmd')"

This will compile the document into HTML while executing all the code 
snippets in the document.
~~~


# Part 1: Getting started

This part describes setting up the CodeDJ system from scratch, downloading a 
dataset, and running a query. It is a tutorial for someone who is trying out getting their own dataset, and 
writing their own queries. This part consists of the following sections:

TODO

These two components are modular: writing queries does not require downloading
a dataset---one is provided with the artifact (details ion the downloading 
section). 

The downloading section requires, well, downloading. If the reather wishes to avoid this,
they can skip that step and use the pre-geneerated dataset provided with the artifact

### Setup

(You can run all the code in this section by executing `scripts/setup.sh`.)

Djanco and Parasite are already isntalled in the artifact image. You can download and build them Parasite using the following two commands:

```bash
rm -rf parasite
git clone https://github.com/PRL-PRG/codedj-parasite.git parasite
cd parasite
cargo build --release
cd ..
```

```bash
git clone https://github.com/PRL-PRG/djanco.git 
cd djanco 
cargo build --release
cd ..
```

### Skipping downloading

We also provide a pre-downloaded dataset in `datasets/toy-dataset` so this step
can be skipped. To skip downloading, move the existing dataset to the path expected by the rest of the tools:

```bash
mv dataset/predownloaded-to-dataset datasets/toy-dataset
```

This provides a small 10-project dataset using Parasite that is the same 
as if the reader downloaded it following the steps in the next section.

### Downloading a toy dataset

We explain how to download a small 10-project dataset using Parasite. 

In order to download projects from GitHub Parasite requires the user have a 
GitHub account and a personal access token. You can generate a token for your 
GitHub account by following the instructions 
[here](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token). 
The token does not need any scopes or permissions.

To create a basic dataset, first create a directory that will contain the 
downloaded. Be aware that datasets tend to be large. 

```{bash}
mkdir -p datasets/toy-dataset/
mkdir -p datasets/toy-dataset/repo_clones
```

Next, specify the list of repositories to include in the dataset in a CSV file.
 The toy dataset will contain the following 10 repositories (4 Python, 4 
 JavaScript, and 2 TypeScript repositories):

```
repository
https://github.com/nodejs/node.git
https://github.com/pixijs/pixi.js.git
https://github.com/angular/angular.git
https://github.com/apache/airflow.git
https://github.com/facebook/react.git
https://github.com/vuejs/vue.git
https://github.com/xonsh/xonsh.git
https://github.com/meteor/meteor.git
https://github.com/3b1b/manim.git
https://github.com/s0md3v/photon.git
```

This file is located at `datasets/toy-dataset-repositories.csv`.

Then, feed the list of repositories to Parasite:

```{bash}
parasite/target/release/parasite --datastore datasets/toy-dataset add datasets/toy-dataset-repositories.csv
```

Next, create a CSV file containing one of more 
[GitHub personal access tokens](https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token). 
No special scopes or permissions are needed on the token. These are used to 
download data using the GitHub REST API and are essential for the downloader
to work.

```
token
fa56454....
```

We cannot provide a file with these for presentation purposes. We assume the
reader prepares their own token file in the current directory at 
`ghtokens.csv`.

The next step is to enter interactive console in Parasite. Provide a path to
the GitHub token file via the ght flag. You can also specify the number of
threads that the downloader will use with the n flag (here we use 8).

```bash
parasite/target/release/parasite --datastore datasets/toy-dataset -ght ghtokens.csv -n 8 --interactive
```

(This executes the command in a new terminal, so it's possible to run in from inside RStudio)

```{bash}
gnome-terminal -e "parasite/target/release/parasite --datastore datasets/toy-dataset -ght ghtokens.csv -n 8 --interactive"
```

![](img/interactive.png)

In interactive console: execute the `loadall` command to load `substore`
information into memory.

```
loadall
```

![](img/loadall.png)

Then, also in *interactive* console: execute `updateall` to start the
downloader. This will cause Parasite to download, process and store information
about each added repository using 8 threads.

```
updateall
```

Wait until the download completes (about 15 minutes for the example dataset).
Exit the downloader (`^C`). The example dataset is ready for querying. 

### Setting up a query

There are two ways in which a query can be written and executed. We prepared a
system that will generate a cargo crate and then generate a run script for all
the queries in the crate. This is the easiest way to use Djanco. Alternatively,
one can create a cargo crate from scratch. We only present the former here.

A pre-generated instance of the crate generated by this process is included in
`queries/my-query-crate`.

First, install the `generate` command for the `cargo` system.

```{bash}
cargo install cargo-generate
```


Then, install the `djanco` command for the `cargo` system.

```{bash}
cargo install --git https://github.com/PRL-PRG/cargo-djanco
```

Generate a cargo crate:

```{bash}
cargo generate --git https://github.com/PRL-PRG/djanco-query-template --name my-query-crate
cd my-query-crate
```

This creates a fully-configured cargo create at location`my-query-crate`
with the following directory structure:

```
my-query-crate/
├── Cargo.toml
├── README.md
└── src
    └── lib.rs
```

Inside the crate, there is a `lib.rs` file with an example query that selects
the top starred project in each language using all available subsets of the
repository.

```rust
use std::path::Path;

use djanco::*;
use djanco::data::*;
use djanco::log::*;
use djanco::csv::*;

use djanco_ext::*;

#[djanco(May, 2021, subsets(All))]
pub fn my_query(database: &Database, _log: &Log, output: &Path) -> Result<(), std::io::Error>  {
    database.projects()
        .group_by(project::Language)
        .sort_by(project::Stars)
        .sample(Top(1))
        .into_csv_in_dir(output, "top_1_project_by_stars_in_each_language.csv")
}
```

Generate a run script for the queries:

```{bash}
cargo djanco
```

This generates a rust program at location `src/bin/djanco.rs` that initializes
the dataset and runs all functions in the crate that are tagged as 
`#[djanco(...)]`.

### Running the query

Build and execute the query using the toy dataset:

```{bash}
cargo run --release --bin djanco -- --dataset-path ../toy-dataset --cache-path cache --output-path output
```

After the query is executed, the results of the query will be available at 
`output/top_1_project_by_stars_in_each_language.csv` [truncated]:

```
language,project_id,substore,url, [...] ,stars, ...
JavaScript,5,JavaScript,https://github.com/vuejs/vue.git, [...] ,181894, [...]
TypeScript,2,TypeScript,https://github.com/angular/angular.git, [...] ,72384, [...]
Python,8,Python,https://github.com/3b1b/manim.git, [...] ,32791, [...]
```

We attach a pregenerated instance of the output of this query at 
`pregenerated/top_1_project_by_stars_in_each_language.csv`. Note that the
values of attributes will have changed over time and the downloader will
acquire the most recent values---preserving historical data requires
updating a dataset over time.

```{bash}
cd ..
```